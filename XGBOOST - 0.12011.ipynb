{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdf9f763-7e98-40eb-84f2-5bf8a36fe775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (1460, 81)\n",
      "Test shape: (1459, 80)\n",
      "\n",
      "Missing values in train:\n",
      "PoolQC          1453\n",
      "MiscFeature     1406\n",
      "Alley           1369\n",
      "Fence           1179\n",
      "MasVnrType       872\n",
      "FireplaceQu      690\n",
      "LotFrontage      259\n",
      "GarageType        81\n",
      "GarageYrBlt       81\n",
      "GarageFinish      81\n",
      "GarageQual        81\n",
      "GarageCond        81\n",
      "BsmtFinType2      38\n",
      "BsmtExposure      38\n",
      "BsmtFinType1      37\n",
      "BsmtCond          37\n",
      "BsmtQual          37\n",
      "MasVnrArea         8\n",
      "Electrical         1\n",
      "dtype: int64\n",
      "\n",
      "Final train shape: (1460, 231)\n",
      "Final test shape: (1459, 230)\n",
      "\n",
      "==================================================\n",
      "Training RandomForest\n",
      "==================================================\n",
      "  Fold 1/5 - RMSE: 0.14888\n",
      "  Fold 2/5 - RMSE: 0.12309\n",
      "  Fold 3/5 - RMSE: 0.15016\n",
      "  Fold 4/5 - RMSE: 0.14605\n",
      "  Fold 5/5 - RMSE: 0.11635\n",
      "\n",
      "RandomForest - Average CV RMSE: 0.13691\n",
      "\n",
      "==================================================\n",
      "Training GradientBoosting\n",
      "==================================================\n",
      "  Fold 1/5 - RMSE: 0.13514\n",
      "  Fold 2/5 - RMSE: 0.11355\n",
      "  Fold 3/5 - RMSE: 0.15835\n",
      "  Fold 4/5 - RMSE: 0.12236\n",
      "  Fold 5/5 - RMSE: 0.10908\n",
      "\n",
      "GradientBoosting - Average CV RMSE: 0.12769\n",
      "\n",
      "==================================================\n",
      "Training XGBoost\n",
      "==================================================\n",
      "  Fold 1/5 - RMSE: 0.13314\n",
      "  Fold 2/5 - RMSE: 0.11698\n",
      "  Fold 3/5 - RMSE: 0.15211\n",
      "  Fold 4/5 - RMSE: 0.11948\n",
      "  Fold 5/5 - RMSE: 0.11223\n",
      "\n",
      "XGBoost - Average CV RMSE: 0.12679\n",
      "\n",
      "==================================================\n",
      "Training LightGBM\n",
      "==================================================\n",
      "  Fold 1/5 - RMSE: 0.13674\n",
      "  Fold 2/5 - RMSE: 0.11591\n",
      "  Fold 3/5 - RMSE: 0.16059\n",
      "  Fold 4/5 - RMSE: 0.12431\n",
      "  Fold 5/5 - RMSE: 0.11270\n",
      "\n",
      "LightGBM - Average CV RMSE: 0.13005\n",
      "\n",
      "==================================================\n",
      "Model Performance Summary\n",
      "==================================================\n",
      "XGBoost: 0.12679\n",
      "GradientBoosting: 0.12769\n",
      "LightGBM: 0.13005\n",
      "RandomForest: 0.13691\n",
      "\n",
      "RandomForest weight: 0.2378\n",
      "\n",
      "GradientBoosting weight: 0.2550\n",
      "\n",
      "XGBoost weight: 0.2568\n",
      "\n",
      "LightGBM weight: 0.2504\n",
      "\n",
      "==================================================\n",
      "Submission file 'submission_house_prices.csv' created.\n",
      "==================================================\n",
      "Individual submission saved: submission_randomforest.csv\n",
      "Individual submission saved: submission_gradientboosting.csv\n",
      "Individual submission saved: submission_xgboost.csv\n",
      "Individual submission saved: submission_lightgbm.csv\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "def concat_df(train_data, test_data):\n",
    "    # Returns a concatenated df of training and test set\n",
    "    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n",
    "\n",
    "def divide_df(all_data, train_len):\n",
    "    # Returns divided dfs of training and test set\n",
    "    return all_data.loc[:train_len-1].copy(), all_data.loc[train_len:].drop(['SalePrice'], axis=1).copy()\n",
    "\n",
    "# Load data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "\n",
    "# Store train length and target\n",
    "train_len = len(df_train)\n",
    "y_train = df_train['SalePrice'].copy()\n",
    "\n",
    "# Log transform target for better distribution\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "df_all = concat_df(df_train, df_test)\n",
    "\n",
    "print(\"Train shape:\", df_train.shape)\n",
    "print(\"Test shape:\", df_test.shape)\n",
    "print(\"\\nMissing values in train:\")\n",
    "print(df_train.isnull().sum()[df_train.isnull().sum() > 0].sort_values(ascending=False))\n",
    "\n",
    "# ============================================\n",
    "# FEATURE ENGINEERING\n",
    "# ============================================\n",
    "\n",
    "# 1. Handle missing values strategically\n",
    "# Categorical features - fill with 'None' or mode\n",
    "categorical_none = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                    'BsmtFinType2', 'FireplaceQu', 'GarageType', 'GarageFinish', \n",
    "                    'GarageQual', 'GarageCond', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "for col in categorical_none:\n",
    "    df_all[col] = df_all[col].fillna('None')\n",
    "\n",
    "# MSZoning - fill with mode\n",
    "df_all['MSZoning'] = df_all['MSZoning'].fillna(df_all['MSZoning'].mode()[0])\n",
    "\n",
    "# Utilities - mostly same value, can drop\n",
    "df_all = df_all.drop(['Utilities'], axis=1)\n",
    "\n",
    "# Functional - fill with most common\n",
    "df_all['Functional'] = df_all['Functional'].fillna('Typ')\n",
    "\n",
    "# Exterior - fill with mode\n",
    "df_all['Exterior1st'] = df_all['Exterior1st'].fillna(df_all['Exterior1st'].mode()[0])\n",
    "df_all['Exterior2nd'] = df_all['Exterior2nd'].fillna(df_all['Exterior2nd'].mode()[0])\n",
    "\n",
    "# Electrical - fill with mode\n",
    "df_all['Electrical'] = df_all['Electrical'].fillna(df_all['Electrical'].mode()[0])\n",
    "\n",
    "# KitchenQual - fill with mode\n",
    "df_all['KitchenQual'] = df_all['KitchenQual'].fillna(df_all['KitchenQual'].mode()[0])\n",
    "\n",
    "# SaleType - fill with mode\n",
    "df_all['SaleType'] = df_all['SaleType'].fillna(df_all['SaleType'].mode()[0])\n",
    "\n",
    "# Numeric features - fill with 0 or median\n",
    "df_all['LotFrontage'] = df_all.groupby('Neighborhood')['LotFrontage'].transform(\n",
    "    lambda x: x.fillna(x.median()))\n",
    "\n",
    "numeric_zero = ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', \n",
    "                'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt', 'GarageCars', \n",
    "                'GarageArea', 'MasVnrArea']\n",
    "\n",
    "for col in numeric_zero:\n",
    "    df_all[col] = df_all[col].fillna(0)\n",
    "\n",
    "df_all['MasVnrType'] = df_all['MasVnrType'].fillna('None')\n",
    "\n",
    "# 2. Create new features\n",
    "# Total square footage\n",
    "df_all['TotalSF'] = df_all['TotalBsmtSF'] + df_all['1stFlrSF'] + df_all['2ndFlrSF']\n",
    "\n",
    "# Total bathrooms\n",
    "df_all['TotalBath'] = (df_all['FullBath'] + 0.5 * df_all['HalfBath'] +\n",
    "                       df_all['BsmtFullBath'] + 0.5 * df_all['BsmtHalfBath'])\n",
    "\n",
    "# Total porch area\n",
    "df_all['TotalPorchSF'] = (df_all['OpenPorchSF'] + df_all['3SsnPorch'] +\n",
    "                          df_all['EnclosedPorch'] + df_all['ScreenPorch'] +\n",
    "                          df_all['WoodDeckSF'])\n",
    "\n",
    "# Has pool, garage, basement, fireplace\n",
    "df_all['HasPool'] = (df_all['PoolArea'] > 0).astype(int)\n",
    "df_all['HasGarage'] = (df_all['GarageArea'] > 0).astype(int)\n",
    "df_all['HasBsmt'] = (df_all['TotalBsmtSF'] > 0).astype(int)\n",
    "df_all['HasFireplace'] = (df_all['Fireplaces'] > 0).astype(int)\n",
    "\n",
    "# House age and remodel age\n",
    "df_all['HouseAge'] = df_all['YrSold'] - df_all['YearBuilt']\n",
    "df_all['RemodelAge'] = df_all['YrSold'] - df_all['YearRemodAdd']\n",
    "\n",
    "# Is remodeled\n",
    "df_all['IsRemodeled'] = (df_all['YearBuilt'] != df_all['YearRemodAdd']).astype(int)\n",
    "\n",
    "# Quality-Area interactions\n",
    "df_all['OverallQual_TotalSF'] = df_all['OverallQual'] * df_all['TotalSF']\n",
    "df_all['OverallQual_GrLivArea'] = df_all['OverallQual'] * df_all['GrLivArea']\n",
    "df_all['OverallQual_GarageCars'] = df_all['OverallQual'] * df_all['GarageCars']\n",
    "\n",
    "# Condition features\n",
    "df_all['TotalQual'] = df_all['OverallQual'] + df_all['OverallCond']\n",
    "df_all['QualCondDiff'] = df_all['OverallQual'] - df_all['OverallCond']\n",
    "\n",
    "# Neighborhood quality (based on median price in training data)\n",
    "df_train_temp, _ = divide_df(df_all, train_len)\n",
    "neighborhood_price = df_train_temp.groupby('Neighborhood')['SalePrice'].median()\n",
    "df_all['NeighborhoodPrice'] = df_all['Neighborhood'].map(neighborhood_price)\n",
    "\n",
    "# Living area per room\n",
    "df_all['TotRmsAbvGrd_Safe'] = df_all['TotRmsAbvGrd'].replace(0, 1)\n",
    "df_all['LivAreaPerRoom'] = df_all['GrLivArea'] / df_all['TotRmsAbvGrd_Safe']\n",
    "df_all = df_all.drop('TotRmsAbvGrd_Safe', axis=1)\n",
    "\n",
    "# Garage age\n",
    "df_all['GarageAge'] = df_all['YrSold'] - df_all['GarageYrBlt']\n",
    "df_all['GarageAge'] = df_all['GarageAge'].replace(-np.inf, 0).replace(np.inf, 0).fillna(0)\n",
    "\n",
    "# Basement finish ratio\n",
    "df_all['BsmtFinRatio'] = df_all['BsmtFinSF1'] / (df_all['TotalBsmtSF'] + 1)\n",
    "\n",
    "# 3. Ordinal encoding for quality features\n",
    "quality_map = {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "quality_cols = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', \n",
    "                'HeatingQC', 'KitchenQual', 'FireplaceQu', \n",
    "                'GarageQual', 'GarageCond', 'PoolQC']\n",
    "\n",
    "for col in quality_cols:\n",
    "    df_all[col] = df_all[col].map(quality_map)\n",
    "\n",
    "# Basement exposure\n",
    "exposure_map = {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4}\n",
    "df_all['BsmtExposure'] = df_all['BsmtExposure'].map(exposure_map)\n",
    "\n",
    "# Basement finish type\n",
    "bsmtfin_map = {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6}\n",
    "df_all['BsmtFinType1'] = df_all['BsmtFinType1'].map(bsmtfin_map)\n",
    "df_all['BsmtFinType2'] = df_all['BsmtFinType2'].map(bsmtfin_map)\n",
    "\n",
    "# Garage finish\n",
    "garagefin_map = {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3}\n",
    "df_all['GarageFinish'] = df_all['GarageFinish'].map(garagefin_map)\n",
    "\n",
    "# Fence\n",
    "fence_map = {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4}\n",
    "df_all['Fence'] = df_all['Fence'].map(fence_map)\n",
    "\n",
    "# 4. Get remaining categorical features for one-hot encoding\n",
    "categorical_features = df_all.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Remove Id columns if present\n",
    "if 'Id' in categorical_features:\n",
    "    categorical_features.remove('Id')\n",
    "\n",
    "# One-hot encode\n",
    "df_all = pd.get_dummies(df_all, columns=categorical_features, drop_first=True)\n",
    "\n",
    "# 5. Handle any remaining missing values\n",
    "df_all = df_all.fillna(0)\n",
    "\n",
    "# Divide back to train and test\n",
    "df_train, df_test = divide_df(df_all, train_len)\n",
    "\n",
    "print(\"\\nFinal train shape:\", df_train.shape)\n",
    "print(\"Final test shape:\", df_test.shape)\n",
    "\n",
    "# ============================================\n",
    "# MODEL TRAINING\n",
    "# ============================================\n",
    "\n",
    "# Drop unnecessary columns\n",
    "drop_cols = ['Id', 'SalePrice']\n",
    "feature_cols = [col for col in df_train.columns if col not in drop_cols]\n",
    "\n",
    "X = df_train[feature_cols]\n",
    "y = y_train_log\n",
    "X_test = df_test[feature_cols]\n",
    "\n",
    "# Robust scaling for features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=3,\n",
    "        max_features='sqrt',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_samples_split=5,\n",
    "        min_samples_leaf=3,\n",
    "        subsample=0.8,\n",
    "        random_state=42\n",
    "    ),\n",
    "    'XGBoost': XGBRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'LightGBM': LGBMRegressor(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        num_leaves=31,\n",
    "        min_child_samples=5,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "N = 5\n",
    "kf = KFold(n_splits=N, shuffle=True, random_state=42)\n",
    "\n",
    "model_predictions = {}\n",
    "model_scores = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {model_name}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    preds_test = np.zeros((len(X_test_scaled), N))\n",
    "    rmse_scores = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled), 1):\n",
    "        X_tr, X_val = X_scaled.iloc[train_idx], X_scaled.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Train model\n",
    "        model.fit(X_tr, y_tr)\n",
    "        \n",
    "        # Validation predictions\n",
    "        y_val_pred = model.predict(X_val)\n",
    "        \n",
    "        # Calculate RMSE on log scale\n",
    "        rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "        rmse_scores.append(rmse)\n",
    "        \n",
    "        print(f\"  Fold {fold}/{N} - RMSE: {rmse:.5f}\")\n",
    "        \n",
    "        # Test predictions\n",
    "        preds_test[:, fold - 1] = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Average predictions\n",
    "    preds_mean = preds_test.mean(axis=1)\n",
    "    model_predictions[model_name] = preds_mean\n",
    "    model_scores[model_name] = np.mean(rmse_scores)\n",
    "    \n",
    "    print(f\"\\n{model_name} - Average CV RMSE: {np.mean(rmse_scores):.5f}\")\n",
    "\n",
    "# ============================================\n",
    "# ENSEMBLE PREDICTIONS\n",
    "# ============================================\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"Model Performance Summary\")\n",
    "print(f\"{'='*50}\")\n",
    "for model_name, score in sorted(model_scores.items(), key=lambda x: x[1]):\n",
    "    print(f\"{model_name}: {score:.5f}\")\n",
    "\n",
    "# Weighted ensemble based on inverse RMSE\n",
    "weights = {}\n",
    "total_inv_rmse = sum(1/score for score in model_scores.values())\n",
    "for model_name, score in model_scores.items():\n",
    "    weights[model_name] = (1/score) / total_inv_rmse\n",
    "    print(f\"\\n{model_name} weight: {weights[model_name]:.4f}\")\n",
    "\n",
    "# Create ensemble prediction\n",
    "ensemble_pred_log = sum(model_predictions[name] * weight \n",
    "                        for name, weight in weights.items())\n",
    "\n",
    "# Convert back from log scale\n",
    "ensemble_pred = np.expm1(ensemble_pred_log)\n",
    "\n",
    "# Create submission\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": df_test[\"Id\"],\n",
    "    \"SalePrice\": ensemble_pred\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission_house_prices.csv\", index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Submission file 'submission_house_prices.csv' created.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Also save individual model predictions\n",
    "for model_name, preds_log in model_predictions.items():\n",
    "    preds = np.expm1(preds_log)\n",
    "    sub = pd.DataFrame({\n",
    "        \"Id\": df_test[\"Id\"],\n",
    "        \"SalePrice\": preds\n",
    "    })\n",
    "    filename = f\"submission_{model_name.lower()}.csv\"\n",
    "    sub.to_csv(filename, index=False)\n",
    "    print(f\"Individual submission saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b9bb6a-5226-45fe-9473-2ae56344b456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
